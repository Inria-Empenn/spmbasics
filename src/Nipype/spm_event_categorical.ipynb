{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "from nipype.interfaces import fsl \n",
    "from nipype.interfaces import spm\n",
    "from nipype.interfaces.spm import (Realign, SliceTiming, Coregister,  NewSegment,  Normalize12, Smooth)\n",
    "from nipype.interfaces.spm import Level1Design, EstimateModel, EstimateContrast\n",
    "from nipype.algorithms.modelgen import SpecifySPMModel\n",
    "from nipype.interfaces import matlab as mlab\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "import nipype.interfaces.utility as util \n",
    "from nipype.algorithms import rapidart as ra\n",
    "from nipype.interfaces.utility import Function, IdentityInterface\n",
    "import nipype.pipeline.engine as pe\n",
    "import nipype.interfaces.io as nio\n",
    "from nipype.interfaces.base import Bunch\n",
    "from nipype import DataGrabber, Workflow, Node\n",
    "from scipy.io.matlab import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary to let nipype know about matlab path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    }
   ],
   "source": [
    "spm.SPMCommand.set_mlab_paths(paths=os.path.abspath(os.path.join(os.environ['HOME'], 'Documents/MATLAB/spm12/')), matlab_cmd='/soft/matlab_hd/R2020b/bin/glnxa64/MATLAB -nodesktop -nosplash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlab.MatlabCommand.set_default_matlab_cmd(\"/soft/matlab_hd/R2020b/bin/glnxa64/MATLAB  -nodesktop -nosplash\")\n",
    "mlab.MatlabCommand.set_default_paths(os.path.abspath(os.path.join(os.environ['HOME'], 'Documents/MATLAB/spm12/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spm.SPMCommand().version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsl.FSLCommand.set_default_output_type('NIFTI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join(os.environ['HOME'], 'spmbasics/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = os.path.join(base_dir, 'output')\n",
    "data_dir = os.path.abspath(os.path.join(base_dir, 'face_rep'))\n",
    "output_dir = 'datasink'\n",
    "working_dir = 'workingdir'\n",
    "\n",
    "# list of subject identifiers\n",
    "subject_list = ['M03953']\n",
    "\n",
    "# TR of functional images\n",
    "TR = 2.\n",
    "\n",
    "\n",
    "# Smoothing width used during preprocessing\n",
    "fwhm = [8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add how to refer sots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = loadmat(os.path.join(data_dir, \"sots.mat\"), struct_as_record=False)\n",
    "sot = mat['sot'][0]\n",
    "#itemlag = mat['itemlag'][0]\n",
    "\n",
    "subjectinfo = [\n",
    "    Bunch(\n",
    "        conditions=['N1', 'N2', 'F1', 'F2'],\n",
    "        onsets=[sot[0], sot[1], sot[2], sot[3]],\n",
    "        durations=[[0], [0], [0], [0]],\n",
    "        amplitudes=None,\n",
    "        tmod=None,\n",
    "        pmod=None,\n",
    "        regressor_names=None,\n",
    "        regressors=None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design matrix setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond1 = ('positive effect of condition', 'T',\n",
    "         ['N1*bf(1)', 'N2*bf(1)', 'F1*bf(1)', 'F2*bf(1)'], [1, 1, 1, 1])\n",
    "cond2 = ('positive effect of condition_dtemo', 'T',\n",
    "         ['N1*bf(2)', 'N2*bf(2)', 'F1*bf(2)', 'F2*bf(2)'], [1, 1, 1, 1])\n",
    "cond3 = ('positive effect of condition_ddisp', 'T',\n",
    "         ['N1*bf(3)', 'N2*bf(3)', 'F1*bf(3)', 'F2*bf(3)'], [1, 1, 1, 1])\n",
    "# non-famous > famous\n",
    "fam1 = ('positive effect of Fame', 'T',\n",
    "        ['N1*bf(1)', 'N2*bf(1)', 'F1*bf(1)', 'F2*bf(1)'], [1, 1, -1, -1])\n",
    "fam2 = ('positive effect of Fame_dtemp', 'T',\n",
    "        ['N1*bf(2)', 'N2*bf(2)', 'F1*bf(2)', 'F2*bf(2)'], [1, 1, -1, -1])\n",
    "fam3 = ('positive effect of Fame_ddisp', 'T',\n",
    "        ['N1*bf(3)', 'N2*bf(3)', 'F1*bf(3)', 'F2*bf(3)'], [1, 1, -1, -1])\n",
    "# rep1 > rep2\n",
    "rep1 = ('positive effect of Rep', 'T',\n",
    "        ['N1*bf(1)', 'N2*bf(1)', 'F1*bf(1)', 'F2*bf(1)'], [1, -1, 1, -1])\n",
    "rep2 = ('positive effect of Rep_dtemp', 'T',\n",
    "        ['N1*bf(2)', 'N2*bf(2)', 'F1*bf(2)', 'F2*bf(2)'], [1, -1, 1, -1])\n",
    "rep3 = ('positive effect of Rep_ddisp', 'T',\n",
    "        ['N1*bf(3)', 'N2*bf(3)', 'F1*bf(3)', 'F2*bf(3)'], [1, -1, 1, -1])\n",
    "int1 = ('positive interaction of Fame x Rep', 'T',\n",
    "        ['N1*bf(1)', 'N2*bf(1)', 'F1*bf(1)', 'F2*bf(1)'], [-1, -1, -1, 1])\n",
    "int2 = ('positive interaction of Fame x Rep_dtemp', 'T',\n",
    "        ['N1*bf(2)', 'N2*bf(2)', 'F1*bf(2)', 'F2*bf(2)'], [1, -1, -1, 1])\n",
    "int3 = ('positive interaction of Fame x Rep_ddisp', 'T',\n",
    "        ['N1*bf(3)', 'N2*bf(3)', 'F1*bf(3)', 'F2*bf(3)'], [1, -1, -1, 1])\n",
    "\n",
    "contf1 = ['average effect condition', 'F', [cond1, cond2, cond3]]\n",
    "contf2 = ['main effect Fam', 'F', [fam1, fam2, fam3]]\n",
    "contf3 = ['main effect Rep', 'F', [rep1, rep2, rep3]]\n",
    "contf4 = ['interaction: Fam x Rep', 'F', [int1, int2, int3]]\n",
    "contrast_list = [\n",
    "    cond1, cond2, cond3, fam1, fam2, fam3, rep1, rep2, rep3, int1, int2, int3,\n",
    "    contf1, contf2, contf3, contf4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SpecifyModel - Generates SPM-specific Model\n",
    "modelspec = Node(SpecifySPMModel(concatenate_runs=False,\n",
    "                                 input_units='scans',\n",
    "                                 output_units='scans',\n",
    "                                 time_repetition=TR,\n",
    "                                 high_pass_filter_cutoff=128,\n",
    "                                 subject_info = subjectinfo),\n",
    "                 name=\"modelspec\")\n",
    "\n",
    "# Level1Design - Generates an SPM design matrix same as the first level tutorial\n",
    "level1design = Node(Level1Design(bases={'hrf': {'derivs': [0, 0]}},\n",
    "                                 timing_units='scans',\n",
    "                                 interscan_interval=TR,\n",
    "                                 volterra_expansion_order=1, # no model interction\n",
    "                                 flags={'mthresh': 0.8},\n",
    "                                 global_intensity_normalization='none',\n",
    "                                 microtime_onset=12,\n",
    "                                 microtime_resolution=24,\n",
    "                                 factor_info = [dict(name = 'Fame', levels = 2),\n",
    "                                                dict(name = 'Rep', levels = 2)],\n",
    "                                 model_serial_correlations='AR(1)'), #matlabbatch{1}.spm.stats.fmri_spec.cvi = 'AR(1)';\n",
    "                    name=\"level1design\")\n",
    "\n",
    "# EstimateModel - estimate the parameters of the model\n",
    "level1estimate = Node(EstimateModel(estimation_method={'Classical': 1}),\n",
    "                      write_residuals=False, \n",
    "                      name=\"level1estimate\")\n",
    "\n",
    "# EstimateContrast - estimates contrasts\n",
    "level1conest = Node(EstimateContrast(contrasts = contrast_list),\n",
    "                    use_derivs=True, \n",
    "                    name=\"level1conest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['subject_id',\n",
    "                                            'contrasts'],\n",
    "                                    contrasts=contrast_list),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list)]\n",
    "\n",
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "templates = {'func': os.path.join(output_dir, 'preproc', '_subject_id_{subject_id}',\n",
    "                         's{subject_id}_0005_0006_merged.nii'),\n",
    "             'mc_param': os.path.join(output_dir, 'preproc', '_subject_id_{subject_id}',\n",
    "                         'rp_s{subject_id}_0005_0006_merged.txt'),\n",
    "             'outliers': os.path.join(output_dir, 'preproc', '_subject_id_{subject_id}', \n",
    "                             'art.wars{subject_id}_0005_0006_merged_outliers.txt')}\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                               base_directory=experiment_dir,\n",
    "                               sort_filelist=True),\n",
    "                   name=\"selectfiles\")\n",
    "\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory=experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiation of the 1st-level analysis workflow\n",
    "event_cat = Workflow(name='l1analysis')\n",
    "event_cat.base_dir = os.path.join(experiment_dir, working_dir)\n",
    "\n",
    "# Connect up the 1st-level analysis components\n",
    "event_cat.connect([(infosource, selectfiles, [('subject_id', 'subject_id')]),\n",
    "                    (infosource, level1conest, [('contrasts', 'contrasts')]),\n",
    "                    (selectfiles, modelspec, [('func', 'functional_runs')]),\n",
    "                    (selectfiles, modelspec, [('mc_param', 'realignment_parameters'),\n",
    "                                              ('outliers', 'outlier_files')]),\n",
    "                    (modelspec, level1design, [('session_info','session_info')]),\n",
    "                    (level1design, level1estimate, [('spm_mat_file','spm_mat_file')]),\n",
    "                    (level1estimate, level1conest, [('spm_mat_file','spm_mat_file'),\n",
    "                                                    ('beta_images','beta_images'),\n",
    "                                                    ('residual_image','residual_image')]),\n",
    "                    (level1conest, datasink, [('spm_mat_file', '1stLevel.@spm_mat'),\n",
    "                                              ('spmT_images', '1stLevel.@T'),\n",
    "                                              ('con_images', '1stLevel.@con'),\n",
    "                                              ('spmF_images', '1stLevel.@F'),\n",
    "                                              ('ess_images', '1stLevel.@ess')]),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240521-14:14:00,29 nipype.workflow INFO:\n",
      "\t Generated workflow graph: /home/matay/spmbasics/data/output/workingdir/l1analysis/colored_graph.png (graph2use=colored, simple_form=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/matay/spmbasics/data/output/workingdir/l1analysis/colored_graph.png'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_cat.write_graph(graph2use='colored', format='png', dotfilename='colored_graph.dot', simple_form=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240521-14:14:02,347 nipype.workflow INFO:\n",
      "\t Generated workflow graph: /home/matay/spmbasics/data/output/workingdir/l1analysis/flat_graph.png (graph2use=flat, simple_form=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/matay/spmbasics/data/output/workingdir/l1analysis/flat_graph.png'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_cat.write_graph(graph2use='flat', format='png', dotfilename='flat_graph.dot', simple_form=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename='/home/matay/spmbasics/data/output/workingdir/event_cat/colored_graph.png', width=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240521-14:14:06,522 nipype.workflow INFO:\n",
      "\t Workflow l1analysis settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "240521-14:14:06,530 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "240521-14:14:06,530 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"l1analysis.selectfiles\" in \"/home/matay/spmbasics/data/output/workingdir/l1analysis/_subject_id_M03953/selectfiles\".\n",
      "240521-14:14:06,532 nipype.workflow INFO:\n",
      "\t [Node] Executing \"selectfiles\" <nipype.interfaces.io.SelectFiles>\n",
      "240521-14:14:06,533 nipype.workflow INFO:\n",
      "\t [Node] Finished \"selectfiles\", elapsed time 0.000272s.\n",
      "240521-14:14:06,534 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"l1analysis.modelspec\" in \"/home/matay/spmbasics/data/output/workingdir/l1analysis/_subject_id_M03953/modelspec\".\n",
      "240521-14:14:06,538 nipype.workflow INFO:\n",
      "\t [Node] Executing \"modelspec\" <nipype.algorithms.modelgen.SpecifySPMModel>\n",
      "240521-14:14:06,540 nipype.workflow INFO:\n",
      "\t [Node] Finished \"modelspec\", elapsed time 0.001153s.\n",
      "240521-14:14:06,540 nipype.workflow WARNING:\n",
      "\t Storing result file without outputs\n",
      "240521-14:14:06,541 nipype.workflow WARNING:\n",
      "\t [Node] Error on \"l1analysis.modelspec\" (/home/matay/spmbasics/data/output/workingdir/l1analysis/_subject_id_M03953/modelspec)\n",
      "240521-14:14:06,542 nipype.workflow ERROR:\n",
      "\t Node modelspec.a0 failed to run on host ptb-03240070.irisa.fr.\n",
      "240521-14:14:06,542 nipype.workflow ERROR:\n",
      "\t Saving crash info to /home/matay/spmbasics/src/Nipype/crash-20240521-141406-matay-modelspec.a0-73e53a1c-8090-4eb5-a483-7bba3f03ce6c.pklz\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/pipeline/plugins/linear.py\", line 47, in run\n",
      "    node.run(updatehash=updatehash)\n",
      "  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/pipeline/engine/nodes.py\", line 527, in run\n",
      "    result = self._run_interface(execute=True)\n",
      "  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/pipeline/engine/nodes.py\", line 645, in _run_interface\n",
      "    return self._run_command(execute)\n",
      "  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/pipeline/engine/nodes.py\", line 771, in _run_command\n",
      "    raise NodeExecutionError(msg)\n",
      "nipype.pipeline.engine.nodes.NodeExecutionError: Exception raised while executing Node modelspec.\n",
      "\n",
      "Traceback:\n",
      "\tTraceback (most recent call last):\n",
      "\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/interfaces/base/core.py\", line 397, in run\n",
      "\t    runtime = self._run_interface(runtime)\n",
      "\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 521, in _run_interface\n",
      "\t    self._generate_design()\n",
      "\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 654, in _generate_design\n",
      "\t    super(SpecifySPMModel, self)._generate_design(infolist=infolist)\n",
      "\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 511, in _generate_design\n",
      "\t    self._sessinfo = self._generate_standard_design(\n",
      "\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 392, in _generate_standard_design\n",
      "\t    scaled_onset = scale_timings(\n",
      "\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 133, in scale_timings\n",
      "\t    timelist = [np.max([0.0, _scalefactor * t]) for t in timelist]\n",
      "\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 133, in <listcomp>\n",
      "\t    timelist = [np.max([0.0, _scalefactor * t]) for t in timelist]\n",
      "\t  File \"<__array_function__ internals>\", line 200, in amax\n",
      "\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2820, in amax\n",
      "\t    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n",
      "\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n",
      "\t    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "\tValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
      "\n",
      "\n",
      "240521-14:14:06,543 nipype.workflow INFO:\n",
      "\t ***********************************\n",
      "240521-14:14:06,543 nipype.workflow ERROR:\n",
      "\t could not run node: l1analysis.modelspec.a0\n",
      "240521-14:14:06,543 nipype.workflow INFO:\n",
      "\t crashfile: /home/matay/spmbasics/src/Nipype/crash-20240521-141406-matay-modelspec.a0-73e53a1c-8090-4eb5-a483-7bba3f03ce6c.pklz\n",
      "240521-14:14:06,544 nipype.workflow INFO:\n",
      "\t ***********************************\n"
     ]
    },
    {
     "ename": "NodeExecutionError",
     "evalue": "Exception raised while executing Node modelspec.\n\nTraceback:\n\tTraceback (most recent call last):\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/interfaces/base/core.py\", line 397, in run\n\t    runtime = self._run_interface(runtime)\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 521, in _run_interface\n\t    self._generate_design()\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 654, in _generate_design\n\t    super(SpecifySPMModel, self)._generate_design(infolist=infolist)\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 511, in _generate_design\n\t    self._sessinfo = self._generate_standard_design(\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 392, in _generate_standard_design\n\t    scaled_onset = scale_timings(\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 133, in scale_timings\n\t    timelist = [np.max([0.0, _scalefactor * t]) for t in timelist]\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 133, in <listcomp>\n\t    timelist = [np.max([0.0, _scalefactor * t]) for t in timelist]\n\t  File \"<__array_function__ internals>\", line 200, in amax\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2820, in amax\n\t    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n\t    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n\tValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNodeExecutionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevent_cat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/pipeline/engine/workflows.py:638\u001b[0m, in \u001b[0;36mWorkflow.run\u001b[0;34m(self, plugin, plugin_args, updatehash)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m str2bool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_report\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_report_info(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, execgraph)\n\u001b[0;32m--> 638\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdatehash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdatehash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m datestr \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mutcnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m str2bool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexecution\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite_provenance\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n",
      "File \u001b[0;32m~/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/pipeline/plugins/linear.py:82\u001b[0m, in \u001b[0;36mLinearPlugin.run\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(errors) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     77\u001b[0m     error, cause \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m raised. Re-raising first.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     79\u001b[0m         error,\n\u001b[1;32m     80\u001b[0m     )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcause\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/pipeline/plugins/linear.py:47\u001b[0m, in \u001b[0;36mLinearPlugin.run\u001b[0;34m(self, graph, config, updatehash)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_status_callback:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_status_callback(node, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdatehash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdatehash\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     49\u001b[0m     endstatus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexception\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/pipeline/engine/nodes.py:527\u001b[0m, in \u001b[0;36mNode.run\u001b[0;34m(self, updatehash)\u001b[0m\n\u001b[1;32m    524\u001b[0m savepkl(op\u001b[38;5;241m.\u001b[39mjoin(outdir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_inputs.pklz\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs\u001b[38;5;241m.\u001b[39mget_traitsfree())\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Node] Error on \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfullname, outdir)\n",
      "File \u001b[0;32m~/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/pipeline/engine/nodes.py:645\u001b[0m, in \u001b[0;36mNode._run_interface\u001b[0;34m(self, execute, updatehash)\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_hash()\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_results()\n\u001b[0;32m--> 645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/pipeline/engine/nodes.py:771\u001b[0m, in \u001b[0;36mNode._run_command\u001b[0;34m(self, execute, copyfiles)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;66;03m# Always pass along the traceback\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraceback:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_tab(runtime\u001b[38;5;241m.\u001b[39mtraceback)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NodeExecutionError(msg)\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mNodeExecutionError\u001b[0m: Exception raised while executing Node modelspec.\n\nTraceback:\n\tTraceback (most recent call last):\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/interfaces/base/core.py\", line 397, in run\n\t    runtime = self._run_interface(runtime)\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 521, in _run_interface\n\t    self._generate_design()\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 654, in _generate_design\n\t    super(SpecifySPMModel, self)._generate_design(infolist=infolist)\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 511, in _generate_design\n\t    self._sessinfo = self._generate_standard_design(\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 392, in _generate_standard_design\n\t    scaled_onset = scale_timings(\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 133, in scale_timings\n\t    timelist = [np.max([0.0, _scalefactor * t]) for t in timelist]\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/nipype/algorithms/modelgen.py\", line 133, in <listcomp>\n\t    timelist = [np.max([0.0, _scalefactor * t]) for t in timelist]\n\t  File \"<__array_function__ internals>\", line 200, in amax\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2820, in amax\n\t    return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\t  File \"/home/matay/anaconda3/envs/spmbasics/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 86, in _wrapreduction\n\t    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n\tValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n"
     ]
    }
   ],
   "source": [
    "event_cat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
